[
["Variant-statistics.html", "Section 3 Variant statistics 3.1 Process of raw data 3.2 Number of variants", " Section 3 Variant statistics 3.1 Process of raw data Since the raw output of the Snakemake pipeline produces one vcf file per sample (including all contigs of the OligoMM reference genomes) we now produce a single rds file that contains the merged variant information of the whole study. We define a function that iterates over a set of vcf files (vcf.files) #&#39; Processes a list of vcf files #&#39; #&#39; @param vcf.files a list of file path of files in vcf format #&#39; @param contig_mapping mapping file of vcf CHR to OMM reference genomes #&#39; @return a dataframe holding the merged annotated variant information vcfToDataframe &lt;- function(vcf.files, contig_mapping = read.csv2(&quot;data/contig_genome_mapping.csv&quot;, sep =&quot;;&quot;, header=T, stringsAsFactors = F) ) { require(vcfR) res &lt;- list() for (file in vcf.files) { vcf.content &lt;- vcfR::read.vcfR(file, verbose = FALSE ) vcf.fix &lt;- as.data.frame(vcf.content@fix) # contains chr, position and substitution informations vcf.info &lt;- vcfR::INFO2df(vcf.content) # get INFO field, contains DP, AF informations # vcf.ann &lt;- data.frame(do.call(&#39;rbind&#39;, strsplit(as.character(vcf.info$ANN),&#39;|&#39;,fixed = TRUE))) # split ANN field, contains information if files are processed by snpEff if(nrow(vcf.fix) &gt; 0) { dat &lt;- as.data.frame(cbind(vcf.fix[,c(1, 2, 4, 5, 6)], vcf.info[,c(1, 2)])) dat$majorAF &lt;- sapply(dat$AF, minorAfToMajorAf) # transforms e.g. AF of 0.1 to 0.9, 0.9 stays 0.9 and 0.5 stays 0.5 dat$genome &lt;- contig_mapping[match(dat$CHROM, contig_mapping$contig),]$genome # map chr information to genome name e.g. NHMU01000001.1 -&gt; i48 dat$genome_hr &lt;- translateGenomeIdToFullName(dat$genome) dat$mouse.id &lt;- substr(basename(file), 1, 4) # get mouse ID from file name, e.g. &quot;1681&quot; dat$dp &lt;- as.numeric(as.matrix(vcf.info$DP)) res[[basename(file)]] &lt;- dat # add vcf df to list } } df &lt;- as.data.frame(do.call(rbind, res)) # merge list to df return(df) } We apply this function on all 24 files that live in data/raw/lofreq/*.vcf contig_mapping &lt;- read.csv2(&quot;data/contig_genome_mapping.csv&quot;, sep =&quot;;&quot;, header=T, stringsAsFactors = F) # this file contains contig names of the 12 OligoMM genomes vcf.files &lt;- Sys.glob(&quot;data/raw/lofreq/*.vcf&quot;) dat &lt;- suppressWarnings(vcfToDataframe(vcf.files, contig_mapping)) # annotate study metadata dat &lt;- merge(dat, design, by = &quot;mouse.id&quot;) dat$mouse.id &lt;- as.character(as.matrix(dat$mouse.id)) saveRDS(dat, file = &quot;data/rds/variants_unannotated.rds&quot;) The dataset is written to data/rds/variants_unannotated.rds) and will be used in later sections. 3.2 Number of variants 3.2.1 by sample only non-ecoli samples dat &lt;- readRDS(&quot;data/rds/variants_unannotated.rds&quot;) dat &lt;- dat[which(dat$ecoli== FALSE),] This set contains 727 variants found in 12 genomes. The detailed breakdow of variants per genome is as follows. dat$dummy &lt;- 1 dat.by.sample.genome &lt;- aggregate(dummy ~ mouse.id + genome, dat, sum) colnames(dat.by.sample.genome) &lt;- c(&quot;sample&quot;, &quot;genome&quot;, &quot;number_variants&quot;) DT::datatable(dat.by.sample.genome) p &lt;- ggplot(dat.by.sample.genome, aes(x = reorder(sample, number_variants), y = number_variants, fill = genome)) p &lt;- p + geom_bar(stat=&quot;identity&quot;) + coord_flip() + theme_classic() p &lt;- p + ylab(&quot;number of variants&quot;) + xlab(&quot;sample&quot;) + scale_fill_manual(values = omm_colors) plotly::ggplotly(p) Figure 3.1: Number of variants by genome (color) found in samples 3.2.2 by mouse and genome only non-ecoli samples dat$dummy &lt;- 1 dat.by.sample &lt;- aggregate(dummy ~ mouse.id, dat, sum) colnames(dat.by.sample) &lt;- c(&quot;sample&quot;, &quot;number_variants&quot;) DT::datatable(dat.by.sample) p &lt;- ggplot(dat.by.sample, aes(x = reorder(sample, number_variants), y = number_variants)) p &lt;- p + geom_bar(stat=&quot;identity&quot;) + coord_flip() + theme_classic() p &lt;- p + xlab(&quot;number of variants&quot;) + ylab(&quot;sample&quot;) plotly::ggplotly(p) Figure 3.2: number of variants of all 12 OMM genomes by mouse 3.2.3 by extendet metadata only non-ecoli samples dat$dummy &lt;- 1 dat.by.sample.genome2 &lt;- aggregate(dummy ~ mouse.id + genome + generation + ecoli + desc + day + DP, dat, sum) colnames(dat.by.sample.genome2) &lt;- c(&quot;sample&quot;, &quot;genome&quot;, &quot;generation&quot;, &quot;ecoli&quot;, &quot;desc&quot;,&quot;day&quot;,&quot;DP&quot;, &quot;number_variants&quot;) summary(dat$DP) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.0 78.5 200.0 381.4 456.0 2480.0 DP is the filtered depth, at the sample level. This gives you the number of filtered reads that support each of the reported alleles. You can check the variant caller’s documentation to see which filters are applied by default. Only reads that passed the variant caller’s filters are included in this number. However, unlike the AD calculation, uninformative reads are included in DP. DT::datatable(dat.by.sample.genome2) dat$DP &lt;- NULL #dat.by.sample.genome2 &lt;- dat.by.sample.genome2[which(dat.by.sample.genome2$sample != &quot;I_cc&quot; &amp; dat.by.sample.genome2$sample != &quot;I_mi&quot;),] p &lt;- ggplot(dat.by.sample.genome2, aes(x = sample, y = number_variants, fill = genome)) p &lt;- p + geom_bar(stat=&quot;identity&quot;) + theme_classic() p &lt;- p + facet_grid(.~ generation + day, scales = &quot;free_x&quot;) p &lt;- p + ylab(&quot;number of variants&quot;) + xlab(&quot;sample&quot;) + scale_fill_manual(values = omm_colors) print(p) Figure 3.3: Number of variants by genome (color) found in samples #plotly::ggplotly(p) "]
]
