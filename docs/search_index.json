[
["index.html", "Claudia’s data Preface How to generate this report Acknowledgements", " Claudia’s data Philipp C. Muench 2020-03-29 Preface Processing of NGS data is done using Snakemake and not covered by this report yet and will be added at a later stage. In short, preprocessing and analysis (such as bwa alignment and variant calling using Lofreq is defined using a Snakefile and a set of snakemake rules which are run on the HZI server (host) and detailed analysis (such as generation of figures and statistical tests) are done using R markdown on the client machine. How to generate this report In vscode with bookdown addon a server can be started using serve_book bookdown::serve_book(getwd()) This will starts a browser window pointing to http://127.0.0.1:7853 presenting the report written in R Markdown Acknowledgements "],
["Setup.html", "Section 1 Setup 1.1 Workspace setup 1.2 Dependencies 1.3 Data structure", " Section 1 Setup 1.1 Workspace setup We specify the folder where the analysis is located. setwd(&quot;~/projects/oligomm-claudia/&quot;) 1.2 Dependencies Functions that are used frequent are defined in utils.R and are mostly helper functions for data manipulation (e.g. translation of sample ids to groups). Other packages can be load via cran using the install.packages() function. rm(list = ls()) source(&quot;utils.R&quot;) library(&quot;vcfR&quot;) library(&quot;rmdformats&quot;) library(&quot;ggplot2&quot;) library(&quot;reshape2&quot;) library(&quot;ggridges&quot;) library(&quot;knitr&quot;) library(&quot;kableExtra&quot;) library(&quot;plotly&quot;) library(&quot;DT&quot;) library(&quot;rtracklayer&quot;) for rtracklayer you might need curl sudo apt-get install libcurl4-openssl-dev 1.3 Data structure data/raw files from host machine, contains coverage and lofreq data data/annotation annotation files for OMM12 genomes e.g. phage location (pro-hunter, fasta files and Prokka annotation) data/annotation/gff Prokka annotation data/rda processed raw data in rds format generated by 01-load-data.rmd docs html files generated via bookdown::serve_book(getwd()) "],
["study-design.html", "Section 2 Study design 2.1 OligoMM 2.2 Metadata", " Section 2 Study design 2.1 OligoMM ID phylum species YL44 Verrucomicrobia A. muciniphila I48 Bacteroidetes B. caecimuris YL27 Bacteroidetes M. intestinale YL45 Proteobacteria T. muris YL2 Actinobacteria B. longum KB1 Firmicutes E. faecalis KB18 Firmicutes A. muris YL32 Firmicutes C. clostridioforme YL31 Firmicutes F. plautii YL58 Firmicutes B. coccoides I49 Firmicutes L. reuteri I46 Firmicutes C. innocuum 2.2 Metadata design.df &lt;- read.table(&quot;data/sample_mapping.tsv&quot;, header = T, sep = &quot;\\t&quot;) DT::datatable(design.df) "],
["Variant-statistics.html", "Section 3 Variant statistics 3.1 Process of raw data 3.2 Quality of variants 3.3 all samples 3.4 by mouse 3.5 Number of variants 3.6 Vaiant annotation", " Section 3 Variant statistics 3.1 Process of raw data Since the raw output of the Snakemake pipeline produces one vcf file per sample (including all contigs of the OligoMM reference genomes) we now produce a single rds file that contains the merged variant information of the whole study. We define a function that iterates over a set of vcf files (vcf.files) #&#39; Processes a list of vcf files #&#39; #&#39; @param vcf.files a list of file path of files in vcf format #&#39; @param contig_mapping mapping file of vcf CHR to OMM reference genomes #&#39; @param gff.dff merged gff data from reference genomes #&#39; @return a dataframe holding the merged annotated variant information vcfToDataframe &lt;- function(vcf.files, contig_mapping = read.csv2(&quot;data/contig_genome_mapping.csv&quot;), gff.df = gff.df) { require(vcfR) res &lt;- list() for (file in vcf.files) { vcf.content &lt;- vcfR::read.vcfR(file, verbose = FALSE) vcf.fix &lt;- as.data.frame(vcf.content@fix) # contains chr, position and substitution informations vcf.info &lt;- vcfR::INFO2df(vcf.content) # get INFO field, contains DP, AF informations # vcf.ann &lt;- data.frame(do.call(&#39;rbind&#39;, # strsplit(as.character(vcf.info$ANN),&#39;|&#39;,fixed = TRUE))) # split ANN field, # contains information if files are processed by snpEff if (nrow(vcf.fix) &gt; 0) { dat &lt;- as.data.frame(cbind(vcf.fix[, c(1, 2, 4, 5, 6)], vcf.info[, c(1, 2)])) dat$majorAF &lt;- sapply(dat$AF, minorAfToMajorAf) # transforms e.g. AF of 0.1 to 0.9, 0.9 stays 0.9 and 0.5 stays 0.5 dat$genome &lt;- contig_mapping[match(dat$CHROM, contig_mapping$contig), ]$genome # map chr information to genome name e.g. NHMU01000001.1 -&gt; i48 dat$genome_hr &lt;- translateGenomeIdToFullName(dat$genome) dat$mouse.id &lt;- substr(basename(file), 1, 4) # get mouse ID from file name, e.g. &#39;1681&#39; dat$dp &lt;- as.numeric(as.matrix(vcf.info$DP)) # annotate overlay of gene dat$orf_desc &lt;- as.character(as.matrix(apply(dat, 1, getGeneByPosition, gff = gff, pos.column = 2, chr.column = 1))) res[[basename(file)]] &lt;- dat # add vcf df to list } } df &lt;- as.data.frame(do.call(rbind, res)) # merge list to df return(df) } We apply this function on all 24 files that live in data/raw/lofreq/*.vcf # merge gff annotaions gff.files &lt;- Sys.glob(&quot;data/annotation/gff/*.gff&quot;) gff.df &lt;- NULL for (gff.file in gff.files) { message(gff.file) gff &lt;- rtracklayer::readGFF(gff.file) # subset since different columns are present on gff files relevant &lt;- data.frame(start = gff$start, end = gff$end, type = as.character(as.matrix(gff$type)), gene = as.character(as.matrix(gff$gene)), product = as.character(as.matrix(gff$product)), chr = as.character(as.matrix(gff$seqid))) relevant$genome &lt;- substr(basename(gff.file), 1, nchar(basename(gff.file)) - 4) gff.df &lt;- rbind(gff.df, relevant) } contig_mapping &lt;- read.csv2(&quot;data/contig_genome_mapping.csv&quot;, sep = &quot;;&quot;, header = T, stringsAsFactors = F) # this file contains contig names of the 12 OligoMM genomes vcf.files &lt;- Sys.glob(&quot;data/raw/lofreq/*.vcf&quot;) dat &lt;- suppressWarnings(vcfToDataframe(vcf.files, contig_mapping, gff.df = gff.df)) # annotate study metadata dat &lt;- merge(dat, design.df, by = &quot;mouse.id&quot;) dat$mouse.id &lt;- as.character(as.matrix(dat$mouse.id)) dat[which(dat$orf_desc == &quot;character(0)&quot;), ]$orf_desc &lt;- NA dat[which(dat$orf_desc == &quot;hypothetical protein&quot;), ]$orf_desc &lt;- NA saveRDS(dat, file = &quot;data/rds/variants.rds&quot;) The dataset is written to data/rds/variants.rds). 3.2 Quality of variants DP is the filtered depth, at the sample level. This gives you the number of filtered reads that support each of the reported alleles. You can check the variant caller’s documentation to see which filters are applied by default. Only reads that passed the variant caller’s filters are included in this number. However, unlike the AD calculation, uninformative reads are included in DP. dat &lt;- readRDS(&quot;data/rds/variants.rds&quot;) dat &lt;- dat[which(dat$ecoli == FALSE), ] print(summary(dat$dp)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.0 78.5 200.0 381.4 456.0 2480.0 3.3 all samples p &lt;- ggplot(dat, aes(dp, fill = genome)) + geom_histogram() p &lt;- p + theme_classic() + xlab(&quot;filtered depth&quot;) + ylab(&quot;occurence&quot;) p &lt;- p + scale_fill_manual(values = omm_colors) plotly::ggplotly(p) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 3.1: filtred depth of varaints (all samples) 3.4 by mouse p &lt;- ggplot(dat, aes(dp, fill = genome)) + geom_histogram() p &lt;- p + theme_classic() + xlab(&quot;filtered depth&quot;) + ylab(&quot;occurence&quot;) p &lt;- p + scale_fill_manual(values = omm_colors) + facet_wrap(~mouse.id + desc, ncol = 2) p &lt;- p + theme(panel.border = element_blank(), strip.text = element_text(size = 12, colour = &quot;black&quot;), strip.background = element_rect(colour = &quot;white&quot;, fill = &quot;white&quot;)) plotly::ggplotly(p) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 3.2: filtred depth of varaints by mouse 3.5 Number of variants 3.5.1 by sample only non-ecoli samples dat &lt;- readRDS(&quot;data/rds/variants.rds&quot;) dat &lt;- dat[which(dat$ecoli == FALSE), ] This set contains 727 variants found in 12 genomes. The detailed breakdow of variants per genome is as follows. dat$dummy &lt;- 1 dat.by.sample.genome &lt;- aggregate(dummy ~ mouse.id + genome, dat, sum) colnames(dat.by.sample.genome) &lt;- c(&quot;sample&quot;, &quot;genome&quot;, &quot;number_variants&quot;) DT::datatable(dat.by.sample.genome) p &lt;- ggplot(dat.by.sample.genome, aes(x = reorder(sample, number_variants), y = number_variants, fill = genome)) p &lt;- p + geom_bar(stat = &quot;identity&quot;) + coord_flip() + theme_classic() p &lt;- p + ylab(&quot;number of variants&quot;) + xlab(&quot;sample&quot;) + scale_fill_manual(values = omm_colors) plotly::ggplotly(p) Figure 3.3: Number of variants by genome (color) found in samples 3.5.2 by mouse and genome only non-ecoli samples dat$dummy &lt;- 1 dat.by.sample &lt;- aggregate(dummy ~ mouse.id, dat, sum) colnames(dat.by.sample) &lt;- c(&quot;sample&quot;, &quot;number_variants&quot;) DT::datatable(dat.by.sample) p &lt;- ggplot(dat.by.sample, aes(x = reorder(sample, number_variants), y = number_variants)) p &lt;- p + geom_bar(stat = &quot;identity&quot;) + coord_flip() + theme_classic() p &lt;- p + xlab(&quot;number of variants&quot;) + ylab(&quot;sample&quot;) plotly::ggplotly(p) Figure 3.4: number of variants of all 12 OMM genomes by mouse 3.5.3 by extendet metadata only non-ecoli samples dat$dummy &lt;- 1 dat.by.sample.genome2 &lt;- aggregate(dummy ~ mouse.id + genome + generation + ecoli + desc + day, dat, sum) colnames(dat.by.sample.genome2) &lt;- c(&quot;sample&quot;, &quot;genome&quot;, &quot;generation&quot;, &quot;ecoli&quot;, &quot;desc&quot;, &quot;day&quot;, &quot;number_variants&quot;) summary(dat$DP) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.0 78.5 200.0 381.4 456.0 2480.0 DT::datatable(dat.by.sample.genome2) dat$DP &lt;- NULL # dat.by.sample.genome2 &lt;- # dat.by.sample.genome2[which(dat.by.sample.genome2$sample != &#39;I_cc&#39; &amp; # dat.by.sample.genome2$sample != &#39;I_mi&#39;),] p &lt;- ggplot(dat.by.sample.genome2, aes(x = sample, y = number_variants, fill = genome)) p &lt;- p + geom_bar(stat = &quot;identity&quot;) + theme_classic() p &lt;- p + facet_grid(. ~ generation + day, scales = &quot;free_x&quot;) p &lt;- p + ylab(&quot;number of variants&quot;) + xlab(&quot;sample&quot;) + scale_fill_manual(values = omm_colors) print(p) # plotly is not working on this type of plot Figure 3.5: Number of variants by genome (color) found in samples 3.6 Vaiant annotation In this section we visualze the occurence of ORFs and their annotations of overlaying variants. The full table is available in this github repository under data/tables/table1.tsv. 3.6.1 Data 3.6.1.1 Write to table write.table(dat, file = &quot;data/tables/table1.tsv&quot;, sep = &quot;\\t&quot;, row.names = F, quote = F) 3.6.1.2 Aggregate by mouse The total number of variant overlapts to ORF per mouse, ordered by their occurence is below and can in data/tables/table2.tsv dat.all &lt;- aggregate(dummy ~ genome + orf_desc, dat, sum) colnames(dat.all) &lt;- c(&quot;genome&quot;, &quot;orf_annotation&quot;, &quot;occurence&quot;) write.table(dat.all, file = &quot;data/tables/table2.tsv&quot;, sep = &quot;\\t&quot;, row.names = F, quote = F) dat.all &lt;- dat.all[order(dat.all$occurence, decreasing = TRUE), ] DT::datatable(dat.all) 3.6.2 Statistics In total, we identified 727 variants in all 10 samples. Of them, 495 variants map to 87 ORFs with an annotated function 3.6.3 Visualization "],
["Allele-frequency.html", "Section 4 Allele frequency 4.1 major allele frequency", " Section 4 Allele frequency 4.1 major allele frequency p &lt;- ggplot(dat, aes(x = majorAF, y = mouse.id)) p &lt;- p + ggridges::geom_density_ridges(jittered_points = TRUE, position = ggridges::position_points_jitter(width = 0.01, height = 0), point_shape = &quot;|&quot;, point_size = 1, point_alpha = 0.5, alpha = 0.1) p &lt;- p + theme_classic() # p &lt;- p + facet_grid(phase ~., space = &#39;free&#39;, scales= &#39;free&#39;) p &lt;- p + theme(strip.background = element_blank()) p &lt;- p + xlab(&quot;Major allele frequency&quot;) + ylab(&quot;Count&quot;) p ## Picking joint bandwidth of 0.0632 "],
["functin-of-variants.html", "Section 5 Function of variants", " Section 5 Function of variants "]
]
