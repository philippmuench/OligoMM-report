[
["index.html", "Claudia’s data Preface How to generate this report Acknowledgements", " Claudia’s data Philipp C. Muench 2020-03-28 Preface Processing of NGS data is done using Snakemake and not covered by this report yet and will be added at a later stage. In short, preprocessing and analysis (such as bwa alignment and variant calling using Lofreq is defined using a Snakefile and a set of snakemake rules which are run on the HZI server (host) and detailed analysis (such as generation of figures and statistical tests) are done using R markdown on the client machine. How to generate this report In vscode with bookdown addon a server can be started using serve_book bookdown::serve_book(getwd()) This will starts a browser window pointing to http://127.0.0.1:7853 presenting the report written in R Markdown Acknowledgements "],
["Setup.html", "Section 1 Setup 1.1 Workspace setup 1.2 Dependencies 1.3 Data structure", " Section 1 Setup 1.1 Workspace setup We specify the folder where the analysis is located. setwd(&quot;~/projects/oligomm-claudia/&quot;) 1.2 Dependencies Functions that are used frequent are defined in utils.R and are mostly helper functions for data manipulation (e.g. translation of sample ids to groups). Other packages can be load via cran using the install.packages() function. rm(list = ls()) source(&quot;utils.R&quot;) library(&quot;vcfR&quot;) library(&quot;rmdformats&quot;) library(&quot;ggplot2&quot;) library(&quot;reshape2&quot;) library(&quot;ggridges&quot;) library(&quot;knitr&quot;) library(&quot;kableExtra&quot;) library(&quot;plotly&quot;) library(&quot;DT&quot;) library(&quot;rtracklayer&quot;) for rtracklayer you might need curl sudo apt-get install libcurl4-openssl-dev 1.3 Data structure data/raw files from host machine, contains coverage and lofreq data data/annotation annotation files for OMM12 genomes e.g. phage location (pro-hunter, fasta files and Prokka annotation) data/rda processed raw data in rds format generated by 01-load-data.rmd "],
["study-design.html", "Section 2 Study design 2.1 OligoMM 2.2 Metadata", " Section 2 Study design 2.1 OligoMM ID phylum species YL44 Verrucomicrobia A. muciniphila I48 Bacteroidetes B. caecimuris YL27 Bacteroidetes M. intestinale YL45 Proteobacteria T. muris YL2 Actinobacteria B. longum KB1 Firmicutes E. faecalis KB18 Firmicutes A. muris YL32 Firmicutes C. clostridioforme YL31 Firmicutes F. plautii YL58 Firmicutes B. coccoides I49 Firmicutes L. reuteri I46 Firmicutes C. innocuum 2.2 Metadata design.df &lt;- read.table(&quot;data/sample_mapping.tsv&quot;, header = T, sep = &quot;\\t&quot;) DT::datatable(design.df) "],
["Variant-statistics.html", "Section 3 Variant statistics 3.1 Process of raw data 3.2 Number of variants", " Section 3 Variant statistics 3.1 Process of raw data Since the raw output of the Snakemake pipeline produces one vcf file per sample (including all contigs of the OligoMM reference genomes) we now produce a single rds file that contains the merged variant information of the whole study. We define a function that iterates over a set of vcf files (vcf.files) #&#39; Processes a list of vcf files #&#39; #&#39; @param vcf.files a list of file path of files in vcf format #&#39; @param contig_mapping mapping file of vcf CHR to OMM reference genomes #&#39; @param gff.dff merged gff data from reference genomes #&#39; @return a dataframe holding the merged annotated variant information vcfToDataframe &lt;- function(vcf.files, contig_mapping = read.csv2(&quot;data/contig_genome_mapping.csv&quot;), gff.df = gff.df) { require(vcfR) res &lt;- list() for (file in vcf.files) { vcf.content &lt;- vcfR::read.vcfR(file, verbose = FALSE) vcf.fix &lt;- as.data.frame(vcf.content@fix) # contains chr, position and substitution informations vcf.info &lt;- vcfR::INFO2df(vcf.content) # get INFO field, contains DP, AF informations # vcf.ann &lt;- data.frame(do.call(&#39;rbind&#39;, # strsplit(as.character(vcf.info$ANN),&#39;|&#39;,fixed = TRUE))) # split ANN field, # contains information if files are processed by snpEff if (nrow(vcf.fix) &gt; 0) { dat &lt;- as.data.frame(cbind(vcf.fix[, c(1, 2, 4, 5, 6)], vcf.info[, c(1, 2)])) dat$majorAF &lt;- sapply(dat$AF, minorAfToMajorAf) # transforms e.g. AF of 0.1 to 0.9, 0.9 stays 0.9 and 0.5 stays 0.5 dat$genome &lt;- contig_mapping[match(dat$CHROM, contig_mapping$contig), ]$genome # map chr information to genome name e.g. NHMU01000001.1 -&gt; i48 dat$genome_hr &lt;- translateGenomeIdToFullName(dat$genome) dat$mouse.id &lt;- substr(basename(file), 1, 4) # get mouse ID from file name, e.g. &#39;1681&#39; dat$dp &lt;- as.numeric(as.matrix(vcf.info$DP)) # annotate overlay of gene dat$genome_desc &lt;- apply(dat, 1, getGeneByPosition, gff = gff, pos.column = 2, chr.column = 1) res[[basename(file)]] &lt;- dat # add vcf df to list } } df &lt;- as.data.frame(do.call(rbind, res)) # merge list to df return(df) } We apply this function on all 24 files that live in data/raw/lofreq/*.vcf # merge gff annotaions gff.files &lt;- Sys.glob(&quot;data/annotation/gff/*.gff&quot;) gff.df &lt;- NULL for (gff.file in gff.files) { message(gff.file) gff &lt;- rtracklayer::readGFF(gff.file) # subset since different columns are present on gff files relevant &lt;- data.frame(start = gff$start, end = gff$end, type = as.character(as.matrix(gff$type)), gene = as.character(as.matrix(gff$gene)), product = as.character(as.matrix(gff$product)), chr = as.character(as.matrix(gff$seqid))) relevant$genome &lt;- substr(basename(gff.file), 1, nchar(basename(gff.file)) - 4) gff.df &lt;- rbind(gff.df, relevant) } contig_mapping &lt;- read.csv2(&quot;data/contig_genome_mapping.csv&quot;, sep = &quot;;&quot;, header = T, stringsAsFactors = F) # this file contains contig names of the 12 OligoMM genomes vcf.files &lt;- Sys.glob(&quot;data/raw/lofreq/*.vcf&quot;) dat &lt;- suppressWarnings(vcfToDataframe(vcf.files, contig_mapping, gff.df = gff.df)) # annotate study metadata dat &lt;- merge(dat, design.df, by = &quot;mouse.id&quot;) dat$mouse.id &lt;- as.character(as.matrix(dat$mouse.id)) saveRDS(dat, file = &quot;data/rds/variants.rds&quot;) The dataset is written to data/rds/variants.rds). 3.2 Number of variants 3.2.1 by sample only non-ecoli samples dat &lt;- readRDS(&quot;data/rds/variants.rds&quot;) dat &lt;- dat[which(dat$ecoli == FALSE), ] This set contains 727 variants found in 12 genomes. The detailed breakdow of variants per genome is as follows. dat$dummy &lt;- 1 dat.by.sample.genome &lt;- aggregate(dummy ~ mouse.id + genome, dat, sum) colnames(dat.by.sample.genome) &lt;- c(&quot;sample&quot;, &quot;genome&quot;, &quot;number_variants&quot;) DT::datatable(dat.by.sample.genome) p &lt;- ggplot(dat.by.sample.genome, aes(x = reorder(sample, number_variants), y = number_variants, fill = genome)) p &lt;- p + geom_bar(stat = &quot;identity&quot;) + coord_flip() + theme_classic() p &lt;- p + ylab(&quot;number of variants&quot;) + xlab(&quot;sample&quot;) + scale_fill_manual(values = omm_colors) plotly::ggplotly(p) Figure 3.1: Number of variants by genome (color) found in samples 3.2.2 by mouse and genome only non-ecoli samples dat$dummy &lt;- 1 dat.by.sample &lt;- aggregate(dummy ~ mouse.id, dat, sum) colnames(dat.by.sample) &lt;- c(&quot;sample&quot;, &quot;number_variants&quot;) DT::datatable(dat.by.sample) p &lt;- ggplot(dat.by.sample, aes(x = reorder(sample, number_variants), y = number_variants)) p &lt;- p + geom_bar(stat = &quot;identity&quot;) + coord_flip() + theme_classic() p &lt;- p + xlab(&quot;number of variants&quot;) + ylab(&quot;sample&quot;) plotly::ggplotly(p) Figure 3.2: number of variants of all 12 OMM genomes by mouse 3.2.3 by extendet metadata only non-ecoli samples dat$dummy &lt;- 1 dat.by.sample.genome2 &lt;- aggregate(dummy ~ mouse.id + genome + generation + ecoli + desc + day, dat, sum) colnames(dat.by.sample.genome2) &lt;- c(&quot;sample&quot;, &quot;genome&quot;, &quot;generation&quot;, &quot;ecoli&quot;, &quot;desc&quot;, &quot;day&quot;, &quot;number_variants&quot;) summary(dat$DP) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.0 78.5 200.0 381.4 456.0 2480.0 DP is the filtered depth, at the sample level. This gives you the number of filtered reads that support each of the reported alleles. You can check the variant caller’s documentation to see which filters are applied by default. Only reads that passed the variant caller’s filters are included in this number. However, unlike the AD calculation, uninformative reads are included in DP. DT::datatable(dat.by.sample.genome2) dat$DP &lt;- NULL # dat.by.sample.genome2 &lt;- # dat.by.sample.genome2[which(dat.by.sample.genome2$sample != &#39;I_cc&#39; &amp; # dat.by.sample.genome2$sample != &#39;I_mi&#39;),] p &lt;- ggplot(dat.by.sample.genome2, aes(x = sample, y = number_variants, fill = genome)) p &lt;- p + geom_bar(stat = &quot;identity&quot;) + theme_classic() p &lt;- p + facet_grid(. ~ generation + day, scales = &quot;free_x&quot;) p &lt;- p + ylab(&quot;number of variants&quot;) + xlab(&quot;sample&quot;) + scale_fill_manual(values = omm_colors) print(p) Figure 3.3: Number of variants by genome (color) found in samples # plotly::ggplotly(p) "],
["Allele-frequency.html", "Section 4 Allele frequency 4.1 major allele frequency", " Section 4 Allele frequency 4.1 major allele frequency p &lt;- ggplot(dat, aes(x = majorAF, y = mouse.id)) p &lt;- p + ggridges::geom_density_ridges(jittered_points = TRUE, position = ggridges::position_points_jitter(width = 0.01, height = 0), point_shape = &quot;|&quot;, point_size = 1, point_alpha = 0.5, alpha = 0.1) p &lt;- p + theme_classic() # p &lt;- p + facet_grid(phase ~., space = &#39;free&#39;, scales= &#39;free&#39;) p &lt;- p + theme(strip.background = element_blank()) p &lt;- p + xlab(&quot;Major allele frequency&quot;) + ylab(&quot;Count&quot;) p ## Picking joint bandwidth of 0.0632 "],
["functin-of-variants.html", "Section 5 Function of variants", " Section 5 Function of variants "]
]
